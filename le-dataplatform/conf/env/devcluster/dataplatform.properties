dataplatform.yarn.job.basedir=/modeling-job
dataplatform.yarn.job.runtime.config=runtimeconfig.properties
dataplatform.customer.basedir=/user/s-analytics/customers
dataplatform.modeling.row.threshold=50
dataplatform.retry.wait.time=30000
dataplatform.sqoopjob.core.pool.size=1
dataplatform.sqoopjob.max.pool.size=6
dataplatform.sqoopjob.queue.capacity=1
dataplatform.queue.scheme=default
dataplatform.hdfs.stack=${LE_STACK}
dataplatform.completedjob.querylimit=1000
dataplatform.python.conda.env=lattice3
dataplatform.python2.conda.env=lattice_20181019
dataplatform.default.python.version=3
# ------
dataplatform.container.virtualcores=1
dataplatform.container.memory=1024
dataplatform.container.map.virtualcores=1
dataplatform.container.reduce.virtualcores=1
dataplatform.container.mapreduce.memory=1024
dataplatform.container.sample.mapreduce.memory=1024
dataplatform.throttle.threshold=1800000
#parallel
dataplatform.model.parallel.enabled=false
dataplatform.model.aws.batch.enabled=false
dataplatform.model.aws.batch.local.enabled=true
dataplatform.sampling.parallel.trainingset.number=4
dataplatform.profiling.parallel.mapper.number=4
dataplatform.container.parallel.map.memory=1024
dataplatform.container.parallel.reduce.memory=1024

#mapreduce property
dataplatform.mapreduce.task.timeout=600000

dataplatform.trustore.jks=
