dataplatform.yarn.job.basedir=/modeling-job
dataplatform.yarn.job.runtime.config=runtimeconfig.properties
dataplatform.customer.basedir=/user/s-analytics/customers
dataplatform.modeling.row.threshold=50
dataplatform.retry.wait.time=60000
dataplatform.sqoopjob.core.pool.size=10
dataplatform.sqoopjob.max.pool.size=90
dataplatform.sqoopjob.queue.capacity=90
dataplatform.completedjob.querylimit=1000
dataplatform.queue.scheme=dedicated
dataplatform.hdfs.stack=${LE_STACK}
dataplatform.python.conda.env=lattice3
dataplatform.python2.conda.env=lattice_20181019
dataplatform.default.python.version=3
# ------
dataplatform.container.virtualcores=1
dataplatform.container.memory=128000
dataplatform.container.map.virtualcores=1
dataplatform.container.reduce.virtualcores=2
dataplatform.container.mapreduce.memory=7168
dataplatform.container.sample.mapreduce.memory=16384
dataplatform.throttle.threshold=604800000

#parallel
dataplatform.model.parallel.enabled=false
dataplatform.model.aws.batch.enabled=true
dataplatform.model.aws.batch.local.enabled=false
dataplatform.sampling.parallel.trainingset.number=10
dataplatform.profiling.parallel.mapper.number=30
dataplatform.container.parallel.map.memory=14336
dataplatform.container.parallel.reduce.memory=21504

#mapreduce property
dataplatform.mapreduce.task.timeout=86400000

dataplatform.trustore.jks=
